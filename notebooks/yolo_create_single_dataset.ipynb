{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BLANK\n",
    "\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import ast\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import skimage.io as io\n",
    "from shapely import Polygon\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import cuda\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm, trange\n",
    "from importlib import reload\n",
    "\n",
    "# Clone FTCNN repo here: https://www.github.com/joeletho/FTCNN.git\n",
    "\n",
    "# Cloned repo directory\n",
    "sys.path.append(\"path/to/ftcnn\")\n",
    "\n",
    "import ftcnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "\n",
    "print(reload(ftcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "\n",
    "has_gpu = cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if has_gpu else 'cpu')\n",
    "print(device)\n",
    "if has_gpu:\n",
    "    print(cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Example directory structure:\n",
    "```\n",
    "Root\n",
    "  ├── FTCNN_YOLO\n",
    "  |         ├── datasets\n",
    "  |         ├── models\n",
    "  ├── NDVI\n",
    "  ├── QGIS\n",
    "  ├── Readme.txt\n",
    "  ├── Shapefiles\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "path_map = {}\n",
    "\n",
    "# Change this to your project path\n",
    "path_map['ROOT'] = Path(\"path/to/project/root\")\n",
    "\n",
    "path_map['PROJECT_NAME'] = 'FTCNN_YOLO'\n",
    "path_map['FTCNN'] = path_map['ROOT'] / path_map[\"PROJECT_NAME\"]\n",
    "path_map['FTCNN_DS'] = path_map['FTCNN'] / 'datasets'\n",
    "path_map['FTCNN_MODELS'] = path_map['FTCNN'] / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "def make_directories(paths_map, verbose=True, exist_ok=False):\n",
    "    if verbose:\n",
    "        print(\"Creating directory structure\")\n",
    "    for name, path in paths_map.items():\n",
    "        if isinstance(path, Path):\n",
    "            if path.is_file():\n",
    "                paths_map[name] = path.resolve()\n",
    "            else:\n",
    "                path = path.resolve()\n",
    "                paths_map[name] = path\n",
    "                path.mkdir(parents=True, exist_ok=exist_ok)\n",
    "                if verbose:\n",
    "                    print('  ',path)\n",
    "    if verbose:\n",
    "        print(\"Complete\")\n",
    "\n",
    "def make_project_paths(root,*, verbose=True, exist_ok=False):    \n",
    "    paths = {'NDVI': Path(root, 'NDVI', 'NDVI Difference Rasters')}\n",
    "    paths['SHAPE_FILES'] = Path(root, 'Shapefiles')\n",
    "\n",
    "    paths['FTCNN_DS_META'] = path_map['FTCNN_DS'] / 'meta'\n",
    "    paths['FTCNN_DS_CSV'] = paths['FTCNN_DS_META'] / 'csv'\n",
    "    paths['FTCNN_DS_SHP'] = paths['FTCNN_DS_META'] / 'shp'\n",
    "    \n",
    "    # Data\n",
    "    paths['PRED_SHP'] = paths['SHAPE_FILES'] / 'ModelPredictions'\n",
    "    paths['SHPZ10_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz10_Only_08-18-24' / 'Treatments_UTMz10_Only_08-18-24.shp'\n",
    "    paths['SHPZ11_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz11_Only_08-18-24' / 'Treatments_UTMz11_Only_08-18-24.shp'\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "        \n",
    "def make_dataset_paths(ds_root, models_root, model_name, *,verbose=True, exist_ok=False):\n",
    "    ds_root = Path(ds_root)\n",
    "    models_root = Path(models_root)\n",
    "    paths = {}\n",
    "        \n",
    "    paths['MODEL_NAME'] = model_name\n",
    "    paths['FTCNN_MODEL'] = models_root / paths['MODEL_NAME']\n",
    "    paths['FTCNN_DS_MODEL'] = ds_root / paths['MODEL_NAME']\n",
    "    paths['FTCNN_DS_MODEL_META'] = paths['FTCNN_DS_MODEL'] / 'meta'\n",
    "    paths['FTCNN_DS_MODEL_SHP'] = paths['FTCNN_DS_MODEL_META'] / 'shp'\n",
    "    paths['FTCNN_DS_MODEL_CSV'] = paths['FTCNN_DS_MODEL_META'] / 'csv'\n",
    "    \n",
    "    paths['FTCNN_DS_DATA'] = paths['FTCNN_DS_MODEL'] / 'meta'\n",
    "    paths['FTCNN_DS_CONFIG_FILE'] = paths['FTCNN_DS_MODEL'] / 'config' / 'data.yaml'\n",
    "    paths['FTCNN_DS_YOLO_DATA_FILE'] = paths['FTCNN_DS_DATA'] / 'yolo_ndvi_ds.csv'\n",
    "    \n",
    "    # Images and labels\n",
    "    paths['FTCNN_DS_IMAGES'] = paths['FTCNN_DS_MODEL'] / 'images'\n",
    "    paths['FTCNN_DS_LABELS'] = paths['FTCNN_DS_MODEL'] / 'labels'\n",
    "    paths['FTCNN_DS_LABELS_GENERATED'] = paths['FTCNN_DS_LABELS'] / 'generated'\n",
    "    \n",
    "    paths['FTCNN_DS_CHIPS'] = paths[\"FTCNN_DS_IMAGES\"] / 'chips'\n",
    "    paths['FTCNN_DS_PNGS'] = paths[\"FTCNN_DS_IMAGES\"] / 'png'\n",
    "    paths['FTCNN_DS_TIFS'] = paths[\"FTCNN_DS_IMAGES\"] / 'tif'\n",
    "    \n",
    "    paths['FTCNN_DS_IMAGES_TRAIN'] = paths['FTCNN_DS_IMAGES'] / 'train'\n",
    "    paths['FTCNN_DS_IMAGES_TEST'] = paths['FTCNN_DS_IMAGES'] / 'test'\n",
    "    paths['FTCNN_DS_IMAGES_VAL'] = paths['FTCNN_DS_IMAGES'] / 'val'\n",
    "    \n",
    "    paths['FTCNN_DS_LABELS_TRAIN'] = paths['FTCNN_DS_LABELS'] / 'train'\n",
    "    paths['FTCNN_DS_LABELS_TEST'] = paths['FTCNN_DS_LABELS'] / 'test'\n",
    "    paths['FTCNN_DS_LABELS_VAL'] = paths['FTCNN_DS_LABELS'] / 'val'\n",
    "\n",
    "    # Metadata\n",
    "\n",
    "    # Zone 10\n",
    "    paths['CSVZ10'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz10.csv'\n",
    "    paths['CSVZ10_NORM'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz10_normalized.csv'\n",
    "    paths['CSVZ10_CLEANED'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz10_normalized_cleaned.csv'\n",
    "    paths['CSVZ10_CHIPPED'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz10_normalized_chipped.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_UTM'] = paths['FTCNN_DS_DATA'] / 'Treatments_z10utm_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL'] = paths['FTCNN_DS_DATA'] / 'Treatments_z10pixel_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL_ENCODED'] = paths['FTCNN_DS_DATA'] / 'Treatments_z10pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PREYOLO'] = paths['FTCNN_DS_DATA'] / 'Treatments_z10pixel_chip_labels_encoded_preyolo.csv'\n",
    "    \n",
    "    # Zone 11\n",
    "    paths['CSVZ11'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz11.csv'\n",
    "    paths['CSVZ11_NORM'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz11_normalized.csv'\n",
    "    paths['CSVZ11_CLEANED'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz11_normalized_cleaned.csv'\n",
    "    paths['CSVZ11_CHIPPED'] = paths['FTCNN_DS_DATA'] / 'Treatments_UTMz11_normalized_chipped.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_UTM'] = paths['FTCNN_DS_DATA'] / 'Treatments_z11utm_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL'] = paths['FTCNN_DS_DATA'] / 'Treatments_z11pixel_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL_ENCODED'] = paths['FTCNN_DS_DATA'] / 'Treatments_z11pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PREYOLO'] = paths['FTCNN_DS_DATA'] / 'Treatments_z11pixel_chip_labels_encoded_preyolo.csv'\n",
    "\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    \n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "    path_map['SHPZ10_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz10_{paths['MODEL_NAME']}.shp\"\n",
    "    path_map['SHPZ11_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz11_{paths['MODEL_NAME']}.shp\"\n",
    "\n",
    "make_project_paths(path_map['ROOT'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "# Class encoder function\n",
    "def classify(row):\n",
    "    geom = row.get('geometry')\n",
    "    return (0, \"Treatment\") if geom is not None and not geom.is_empty and geom.area > 1 else (-1, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BLANK\n",
    "\n",
    "# Dataset configuration settings\n",
    "CHIP_SIZE = [320, 640]\n",
    "YEARS=[2019, 2020, 2021, 2022, 2023]\n",
    "SPLIT=0.75\n",
    "SPLIT_MODE=['all', 'collection']\n",
    "BACKGROUND_BIAS=1.0\n",
    "SHUFFLE_SPLIT=[False, True]\n",
    "SHUFFLE_BACKGROUND=True\n",
    "TREATMENTS = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Error list\n",
    "errors = []\n",
    "\n",
    "# Configure TQDM progress bar\n",
    "total_updates = (\n",
    "    len(TREATMENTS) *\n",
    "    (len(YEARS)-1) *\n",
    "    len(SPLIT_MODE) *\n",
    "    len(SHUFFLE_SPLIT) *\n",
    "    len(CHIP_SIZE)\n",
    "    )\n",
    "root_pbar = trange(total_updates)\n",
    "updates = 0\n",
    "\n",
    "# Get chip size\n",
    "for size in CHIP_SIZE:\n",
    "    # Get treatment\n",
    "    for treatment in TREATMENTS: \n",
    "        # Get years\n",
    "        for i in range(len(YEARS)-1):\n",
    "            years = (YEARS[i], YEARS[i+1])\n",
    "            # Get split mode\n",
    "            for mode in SPLIT_MODE:\n",
    "                # Get split flag\n",
    "                for shuffle_split in SHUFFLE_SPLIT:\n",
    "                    \n",
    "                    # Update pbar message\n",
    "                    root_pbar.set_description(f\"Creating dataset {updates+1}: T: {'all' if treatment == 0 else str(treatment)}, Y: {years[0]},{years[1]}, SM: {mode}, S: {SPLIT}, SS: {shuffle_split}, B: {BACKGROUND_BIAS}, SB: {SHUFFLE_BACKGROUND}\")\n",
    "    \n",
    "                    # Create the model name and create its repository\n",
    "                    path_map['MODEL_NAME'] = f\"yolo_treatments={'all' if treatment == 0 else str(treatment)}_years={years[0]}to{years[1]}_chipsz={size if size is not None else 'Default'}_split={int(SPLIT*100)}_mode={mode}_shuffle-split={shuffle_split}_bg={str(BACKGROUND_BIAS).replace('.','_')}{'' if not SHUFFLE_BACKGROUND else '_shuffle-bg=True'}\"\n",
    "                    make_dataset_paths(\n",
    "                        path_map['FTCNN_DS'], \n",
    "                        path_map['FTCNN_MODELS'],  \n",
    "                        path_map['MODEL_NAME'], \n",
    "                        verbose=False, \n",
    "                        exist_ok=True\n",
    "                    )\n",
    "    \n",
    "                    # Load the master shapefile\n",
    "                    shpz10 = ftcnn.io.load_shapefile(path_map['SHPZ10_SHP'])\n",
    "                    if treatment == 0:\n",
    "                        # All treatments\n",
    "                        shpz10 = shpz10[shpz10['TreatmentT'] != 8]\n",
    "                    else:\n",
    "                        # Individual treatment\n",
    "                        shpz10 = shpz10[shpz10['TreatmentT'] == treatment]\n",
    "    \n",
    "                    # Rename these rows to align filenames that are parsed later\n",
    "                    shpz10.loc[shpz10['Subregion'] == \"Humboldt\", \"Subregion\"] = 'Humboldt4'\n",
    "    \n",
    "                    # Declare the path of the base files used for this dataset\n",
    "                    BASE_FILEPATH = Path(f'base_years={years[0]}to{years[1]}', 'Treatments_UTMz10_Only_08-18-24')\n",
    "                    \n",
    "                    # Save the files\n",
    "                    ftcnn.io.save_as_csv(shpz10, path_map['FTCNN_DS_CSV'] / BASE_FILEPATH.with_suffix('.csv'), exist_ok=True)\n",
    "                    ftcnn.io.save_as_shp(shpz10, path_map['FTCNN_DS_SHP'] / BASE_FILEPATH.with_suffix('.shp'), exist_ok=True)\n",
    "    \n",
    "                    try:\n",
    "                        # Make the dataset using the base shapefile\n",
    "                        yolo_ds = ftcnn.datasets.YOLONDVIDifferenceDataset.create(\n",
    "                                source = path_map['FTCNN_DS_SHP'] / BASE_FILEPATH.with_suffix('.shp'),\n",
    "                                images_dir = ndvi_path,\n",
    "                                output_dir = path_map['FTCNN_DS_MODEL'],\n",
    "                                year_start_column = \"StartYear\",\n",
    "                                year_end_column = \"EndYear\",\n",
    "                                geometry_column = \"geometry\",\n",
    "                                years = years,\n",
    "                                background = None,\n",
    "                                background_ratio = 1.0,\n",
    "                                split= DatasetSplitMode.All,\n",
    "                                split_ratio= 0.7,  # 0.7 (70/30)\n",
    "                                shuffle_split = True,  # True/False\n",
    "                                shuffle_background = True,  # True/False\n",
    "                                generate_labels = True,\n",
    "                                generate_train_data = True,  # True/False\n",
    "                                tile_size=size,\n",
    "                                translate_xy = True,  # True/False\n",
    "                                class_encoder= encode_classes,  # None or callback(row)\n",
    "                                exist_ok = True,  # True/False\n",
    "                                clear_output_dir = True,  # True/False\n",
    "                                save_shp = True,  # True/False\n",
    "                                save_gpkg = True,  # True/False\n",
    "                                save_csv = True,  # True/False\n",
    "                                pbar_leave = True,  # True/False\n",
    "                                convert_to_png = True,\n",
    "                                use_segments = True,\n",
    "                                num_workers = 8,\n",
    "                            )\n",
    "                        if len(yolo_ds.images) < 40:\n",
    "                            # If the size is too small the dataset encounters issues so we limit it to a \n",
    "                            # size that may provide a decent number of images for training\n",
    "                            raise ValueError(\"Too few images to be viable dataset\")\n",
    "    \n",
    "                        # (Optional) Change the root path of the dataset to the target directory where it will be used later on\n",
    "                        yolo_ds.generate_yaml_file(\n",
    "                            root_abs_path=Path(SOME_OTHER_PATH, path_map['MODEL_NAME']),\n",
    "                            dest_abs_path=path_map['FTCNN_DS_MODEL'] / 'config',\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        # Append the error message and remove the created files\n",
    "                        errors.append(f\"{path_map['MODEL_NAME']}: {e}\")\n",
    "                        shutil.rmtree(path_map['FTCNN_DS_MODEL'])\n",
    "    \n",
    "                    # Updae the pbar and update counter\n",
    "                    root_pbar.update()\n",
    "                    updates += 1\n",
    "\n",
    "root_pbar.set_description(f\"Dataset completed with {len(errors)} errors.\")\n",
    "root_pbar.refresh()\n",
    "root_pbar.close()\n",
    "\n",
    "if len(errors) > 0:\n",
    "    print(\"The following errors occurred:\\n\", \"\\n\".join(errors), file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors\n",
    "There may be errors that are encountered that resemble `RuntimeWarning: Value '/path/to/some/image.tif' of field path has been truncated to 254 characters.  This warning will not be emitted any more for that layer.`\n",
    "This is because the filepath associated with the image is longer than what is acceptable in a Shapefile. It is OK to ignore these errors, unless you need to retain that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
